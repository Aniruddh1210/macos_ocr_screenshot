#!/usr/bin/env bash
# Unified OCR screenshot tool for macOS
# - Interactive selection via screencapture
# - OCR via Vision (default) or Tesseract
# - Copies text to clipboard and opens in TextEdit

set -euo pipefail

# Determine project root relative to this script (scripts/ directory one level down)
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ROOT_DIR="$(cd "${SCRIPT_DIR}/.." && pwd)"

# Log file for debugging Shortcuts issues
LOG_FILE="/tmp/ocrshot_debug.log"
# Try to log, but don't fail if we can't write
{
  echo "=== OCR Screenshot Run: $(date) ===" >&2
  echo "SCRIPT_DIR: $SCRIPT_DIR" >&2
  echo "ROOT_DIR: $ROOT_DIR" >&2
  echo "PWD: $(pwd)" >&2
  echo "USER: ${USER:-unknown}" >&2
  echo "SHELL: ${SHELL:-unknown}" >&2
  echo "Arguments: $*" >&2
} >> "$LOG_FILE" 2>/dev/null || true

ENGINE="auto"   # auto | vision | tesseract
OPEN_UI=1        # 1=open TextEdit with result, 0=no
KEEP_IMG=0       # 1=keep image, 0=remove
TESS_LANG=${TESS_LANG:-eng}
INPUT_IMAGE=""   # if set, use this image instead of capturing

usage() {
  cat <<EOF
Usage: $(basename "$0") [options]
Options:
  -e, --engine {auto|vision|tesseract}  OCR engine to use (default: auto)
  -l, --lang <code>                     Tesseract language code (default: eng)
  -i, --input <image-path>              Use an existing image instead of taking a screenshot
  -n, --no-open                         Do not open TextEdit with the result
  -k, --keep                            Keep the captured image (in /tmp)
  -h, --help                            Show this help
EOF
}

while [[ $# -gt 0 ]]; do
  case "$1" in
    -e|--engine) ENGINE="$2"; shift 2;;
    -l|--lang) TESS_LANG="$2"; shift 2;;
    -i|--input) INPUT_IMAGE="$2"; shift 2;;
    -n|--no-open) OPEN_UI=0; shift;;
    -k|--keep) KEEP_IMG=1; shift;;
    -h|--help) usage; exit 0;;
    *) echo "Unknown option: $1" >&2; usage; exit 1;;
  esac
done

TMPDIR="/tmp"
IMG_BASE=$(mktemp "$TMPDIR/ocrshot.unified.XXXXXX")
IMG_PATH="${IMG_BASE}.png"
TXT_BASE=$(mktemp "$TMPDIR/ocrtext.unified.XXXXXX")
TXT_PATH="${TXT_BASE}.txt"

if [ -n "$INPUT_IMAGE" ]; then
  if [ ! -f "$INPUT_IMAGE" ]; then
    echo "Input image not found: $INPUT_IMAGE" >&2
    exit 1
  fi
  # Use the provided image directly
  IMG_PATH="$INPUT_IMAGE"
  KEEP_IMG=1  # never delete user's input image
else
  if ! command -v screencapture >/dev/null 2>&1; then
    echo "screencapture command not found (macOS required)." >&2
    exit 1
  fi
  {
    echo "Starting screencapture to: $IMG_PATH" >&2
    screencapture -i -x "$IMG_PATH" 2>&1
  } >> "$LOG_FILE" 2>/dev/null || true

  if [ ! -s "$IMG_PATH" ]; then
    {
      echo "Screenshot file empty or not created" >&2
      ls -la "$IMG_PATH" 2>&1 || echo "File does not exist" >&2
    } >> "$LOG_FILE" 2>/dev/null || true
    # Silent exit when cancelled
    exit 1
  fi
  { echo "Screenshot captured successfully: $(ls -lh "$IMG_PATH")" >&2; } >> "$LOG_FILE" 2>/dev/null || true
fi

run_vision() {
  local ocr_text=""
  local BIN="${ROOT_DIR}/tools/vision_ocr/vision_ocr"
  local SRC="${ROOT_DIR}/tools/vision_ocr/main.swift"
  if [ -x "$BIN" ]; then
    ocr_text=$("$BIN" "$IMG_PATH" 2>/dev/null || true)
  elif [ -f "$SRC" ]; then
    # Run via swift interpreter if binary not built yet
    ocr_text=$(swift "$SRC" "$IMG_PATH" 2>/dev/null || true)
  else
    return 2
  fi
  printf "%s" "$ocr_text"
}

run_tesseract() {
  if ! command -v tesseract >/dev/null 2>&1; then
    return 2
  fi
  tesseract "$IMG_PATH" stdout -l "$TESS_LANG" 2>/dev/null || true
}

OCR_TEXT=""
{ echo "Running OCR with engine: $ENGINE" >&2; } >> "$LOG_FILE" 2>/dev/null || true
case "$ENGINE" in
  vision)
    { echo "Attempting Vision OCR..." >&2; } >> "$LOG_FILE" 2>/dev/null || true
    OCR_TEXT=$(run_vision || true)
    { echo "Vision OCR result length: ${#OCR_TEXT}" >&2; } >> "$LOG_FILE" 2>/dev/null || true
    ;;
  tesseract)
    { echo "Attempting Tesseract OCR..." >&2; } >> "$LOG_FILE" 2>/dev/null || true
    OCR_TEXT=$(run_tesseract || true)
    { echo "Tesseract OCR result length: ${#OCR_TEXT}" >&2; } >> "$LOG_FILE" 2>/dev/null || true
    ;;
  auto)
    { echo "Attempting Vision OCR first..." >&2; } >> "$LOG_FILE" 2>/dev/null || true
    OCR_TEXT=$(run_vision || true)
    { echo "Vision OCR result length: ${#OCR_TEXT}" >&2; } >> "$LOG_FILE" 2>/dev/null || true
    if [ -z "$OCR_TEXT" ]; then
      { echo "Vision failed, trying Tesseract..." >&2; } >> "$LOG_FILE" 2>/dev/null || true
      OCR_TEXT=$(run_tesseract || true)
      { echo "Tesseract OCR result length: ${#OCR_TEXT}" >&2; } >> "$LOG_FILE" 2>/dev/null || true
    fi
    ;;
  *) echo "Invalid engine: $ENGINE" >&2; exit 1;;
esac

if [ -z "$OCR_TEXT" ]; then
  { echo "No text detected by OCR" >&2; } >> "$LOG_FILE" 2>/dev/null || true
  printf "" | pbcopy
else
  { echo "OCR detected ${#OCR_TEXT} characters" >&2; } >> "$LOG_FILE" 2>/dev/null || true
  printf "%s" "$OCR_TEXT" | pbcopy
  { echo "Text copied to clipboard" >&2; } >> "$LOG_FILE" 2>/dev/null || true
fi

printf "%s" "$OCR_TEXT" > "$TXT_PATH"
{ echo "Text saved to: $TXT_PATH" >&2; } >> "$LOG_FILE" 2>/dev/null || true

if [ "$OPEN_UI" = "1" ]; then
  { echo "Opening TextEdit..." >&2; } >> "$LOG_FILE" 2>/dev/null || true
  open -a TextEdit "$TXT_PATH"
fi

{ echo "Showing notification..." >&2; } >> "$LOG_FILE" 2>/dev/null || true
osascript -e 'display notification "OCR complete â€” text copied to clipboard" with title "OCR Screenshot"' 2>/dev/null || true
{ echo "Script completed successfully" >&2; } >> "$LOG_FILE" 2>/dev/null || true

if [ "$KEEP_IMG" != "1" ] && [ -z "$INPUT_IMAGE" ]; then
  rm -f "$IMG_PATH"
fi

# Print to stderr so Shortcuts doesn't try to parse it
echo "Text: $TXT_PATH" >&2
if [ "$KEEP_IMG" = "1" ]; then echo "Image: $IMG_PATH" >&2; fi

exit 0
